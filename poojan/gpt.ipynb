{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyboard\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import tweepy\n",
    "\n",
    "from elevenlabs import generate, play, set_api_key\n",
    "from langchain.agents import initialize_agent, load_tools\n",
    "from langchain.agents.agent_toolkits import ZapierToolkit\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.utilities.zapier import ZapierNLAWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_api_key(\"dcb21c9f4a8176f2f19148f63cde21e4\")\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 5  # duration of each recording in seconds\n",
    "fs = 44100  # sample rate\n",
    "channels = 1  # number of channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(duration, fs, channels):\n",
    "    print(\"Recording...\")\n",
    "    recording = sd.rec(int(duration * fs), samplerate=fs, channels=channels)\n",
    "    sd.wait()\n",
    "    print(\"Finished recording.\")\n",
    "    return recording\n",
    "\n",
    "\n",
    "def transcribe_audio(recording, fs):\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio:\n",
    "        sf.write(temp_audio.name, recording, fs)\n",
    "        temp_audio.close()\n",
    "        with open(temp_audio.name, \"rb\") as audio_file:\n",
    "            transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "        os.remove(temp_audio.name)\n",
    "    return transcript[\"text\"].strip()\n",
    "\n",
    "\n",
    "def play_generated_audio(text, voice=\"Bella\", model=\"eleven_monolingual_v1\"):\n",
    "    audio = generate(text=text, voice=voice, model=model)\n",
    "    play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    llm = OpenAI(openai_api_key='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', temperature=0)\n",
    "\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "    zapier = ZapierNLAWrapper(zapier_nla_api_key=\"sk-ak-jed9SzIRg7R2F5sio6orTRGX5D\")\n",
    "    toolkit = ZapierToolkit.from_zapier_nla_wrapper(zapier)\n",
    "\n",
    "    # tools = [TweeterPostTool()] + toolkit.get_tools() + load_tools([\"human\"])\n",
    "\n",
    "    tools = toolkit.get_tools() + load_tools([\"human\"])\n",
    "\n",
    "    agent = initialize_agent(tools, llm, memory=memory, agent=\"conversational-react-description\", verbose=True)\n",
    "\n",
    "    while True:\n",
    "        print(\"Press spacebar to start recording.\")\n",
    "        keyboard.wait(\"space\")  # wait for spacebar to be pressed\n",
    "        recorded_audio = record_audio(duration, fs, channels)\n",
    "        message = transcribe_audio(recorded_audio, fs)\n",
    "        print(f\"You: {message}\")\n",
    "        assistant_message = agent.run(message)\n",
    "        play_generated_audio(assistant_message)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
