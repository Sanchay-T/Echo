{% load static %}
<!DOCTYPE html>
<html>

<head>
  <title>Professional HTML Template</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
    }

    .container {
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      height: 100vh;
      background-color: #f2f2f2;
    }



    .button-container {
      display: flex;
      justify-content: center;
      margin-top: 10px;
    }

    button {
      padding: 10px 20px;
      border: none;
      background-color: #007bff;
      color: #fff;
      font-size: 16px;
      font-weight: bold;
      cursor: pointer;
    }

    button:disabled {
      background-color: #ccc;
      cursor: not-allowed;
    }

    .chatbot-container {
      width: 100%;
      margin: 0 auto;
      padding: 20px;
      border: 1px solid #ccc;
      border-radius: 10px;
    }

    .chat-area {
      min-height: 5rem;
      overflow-y: auto;
      border: 1px solid #ccc;
      border-radius: 5px;
      padding: 10px;
      background-color: white;

    }

    .user-message {
      background-color: #f2f2f2;
    }

    .bot-message{
      background-color: #e5f1ff;
    }

    .bot-message:not(:first-child) {
      margin-top: 1rem;
    }

    .mic-button {
      display: inline-block;
      padding: 10px;
      background-color: #007bff;
      color: #fff;
      border: none;
      border-radius: 50%;
      cursor: pointer;
    }

    .mic-button.disabled {
      opacity: 0.5;
      cursor: not-allowed;
    }

    .mic-button.enabled {
      opacity: 1;
      cursor: pointer;
    }

    .loading-animation {
      display: none; 
      text-align: center;
      padding: 10px;
    }

    #chat_load_gif{
      float:left;
      width: 2.5rem;
    }
  </style>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-4bw+/aepP/YC94hEpVNVgiZdgIC5+VKNBQNGCHeKRQN+PtmoHDEXuppvnDJzQIu9" crossorigin="anonymous" />



  <script src="https://www.WebRTC-Experiment.com/RecordRTC.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/2.3.0/socket.io.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io-stream/0.9.1/socket.io-stream.js"></script>
</head>

<body>
  <div class="container">

    <iframe src="http://192.168.217.162:8501" width="100%" height="600" style="border:none;"></iframe>

    <p>
      This is the documentation for the ElevenLabs API. You can use this API
      to use our service programmatically, this is done by using your
      xi-api-key.You can view your xi-api-key using the 'Profile' tab on
      https://elevenlabs.io. Our API is experimental so all endpoints are
      subject to change.
    </p>


    <div class="chatbot-container">
      <div class="chat-area" id="chatArea">
        <div id="chat_holder"></div>
        <div class="loading-animation" id="loadingAnimation">
          <img id="chat_load_gif" src="{% static 'chat_load.gif' %}" alt="Loading..."> <!-- Replace "loading.gif" with your animated GIF URL -->
        </div>
        <!-- Chat messages will be added here dynamically -->
      </div>
      <div>
        <button class="mic-button disabled" id="micButton">ðŸŽ¤</button>
      </div>
    </div>


    <div class="recorded_audio">
      <audio controls id="recordedAudio"></audio>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/js/bootstrap.bundle.min.js"
      integrity="sha384-HwwvtgBNo3bZJJLYd8oVXjrBZt8cqVSpeBNS5n7C8IVInixGAoxmnlMuBnhbgrkm" crossorigin="anonymous">
    </script>

    <script src="https://code.jquery.com/jquery-3.7.0.min.js"
      integrity="sha256-2Pmvv0kuTBOenSvLm6bvfBSSHrUJ+3A7x6P5Ebd07/g=" crossorigin="anonymous"></script>

    <script>
      $(document).ready(function () {

        let chat_load_anim = document.getElementById("loadingAnimation");
        function showLoadingAnimation() {
          console.log("Show loading animation");
          chat_load_anim.style.display = "block";
        }

        function hideLoadingAnimation() {
          chat_load_anim.style.display = "none";
        }
        const chunk_container = $("#chunk_container");


        // Chatbot edits 
        const chatHolder = document.getElementById("chat_holder");
        const micButton = document.getElementById("micButton");
        const recordedAudio = document.getElementById("recordedAudio");
        let recordedChunks = [];
        let h = 1;
        let isMicOn = false;

        micButton.addEventListener("click", toggleMic);

        //  <-- My new edit -->

        const chatSocket = new WebSocket(
          "ws://" + window.location.host + "/ws/live_cb/"
        );

        chatSocket.onmessage = function (e) {
          hideLoadingAnimation();
          const data = JSON.parse(e.data);

          if (data.audio_array) {
            playReceivedAudio(data.audio_array);
          }
          console.log("Data ", data);
          addMessage(data.message, "bot");
        };

        chatSocket.onclose = function (e) {
          console.error("Chat socket closed unexpectedly");
        };


        
        function playReceivedAudio(audioData) {
          let byteCharacters = atob(audioData);
        let byteNumbers = Array.prototype.slice.call(byteCharacters).map((char) => char.charCodeAt(0));
        let byteArray = new Uint8Array(byteNumbers);

        // Create a blob and generate a blob URL
        let blob = new Blob([byteArray], {type: 'audio/mpeg'}); // change 'audio/mpeg' with the correct mime type of your audio
        let url = URL.createObjectURL(blob);

        // Create an audio element and play
        let audio = new Audio(url);
        audio.play();
      }

      

      // Simulate the received bytes array (replace this with your actual received bytes array)
   

        function toggleMic() {
          isMicOn = !isMicOn;

          if (isMicOn) {
            micButton.classList.remove("disabled");
            micButton.classList.add("enabled");
            const startRecordingEvent = {
              event: 'start_recording'
            };
            chatSocket.send(JSON.stringify(startRecordingEvent));
            navigator.mediaDevices
              .getUserMedia({
                audio: true,
              })
              .then((stream) => {
                console.log("Stream ", stream);

                // RecordRTC
                recordAudio = RecordRTC(stream, {
                  type: "audio",
                  mimeType: "audio/webm",
                  sampleRate: 44100, // this sampleRate should be the same in your server code

                  // MediaStreamRecorder, StereoAudioRecorder, WebAssemblyRecorder
                  // CanvasRecorder, GifRecorder, WhammyRecorder
                  recorderType: StereoAudioRecorder,

                  // Dialogflow / STT requires mono audio
                  numberOfAudioChannels: 1,

                  timeSlice: 1700,

                  ondataavailable: function (blob) {
                    let data_aud = event.data;
                    recordedChunks.push(data_aud);

                    console.log("Data available", data_aud['buffer']);

                    // reader.onload = function () {
                    const arrayBuffer = data_aud['buffer'];
                    console.log("Array buffer ", data_aud['buffer']);

                    // const jsonData = {
                    //   audio_chunk: arrayBuffer,
                    //   audio_index: h,
                    // };

                    chatSocket.send(arrayBuffer);

                    // };
                    // reader.readAsArrayBuffer(data_aud);


                    chunk_container.append(
                      `<div style="display:flex ; align-items:center;"><span>${h}</span><audio controls src="${URL.createObjectURL(
                    blob
                  )}"></audio></div>`
                    );
                    h++;
                  },
                });

                recordAudio.startRecording();
              })
              .catch((error) => {
                console.error("Error accessing microphone:", error);
              });


          } else {
            showLoadingAnimation();

            micButton.classList.remove("enabled");
            micButton.classList.add("disabled");

            const stopRecordingEvent = {
              event: 'stop_recording'
            };
            chatSocket.send(JSON.stringify(stopRecordingEvent));


            recordAudio.stopRecording(function () {

              recordAudio.getDataURL(function (audioDataURL) {
                var files = {
                  audio: {
                    type: recordAudio.getBlob().type || 'audio/wav',
                    dataURL: audioDataURL
                  }
                };
                recordedAudio.src = files.audio.dataURL;
              });
            });
          }
        }

        function addMessage(message, sender) {
          const messageDiv = document.createElement("div");
          messageDiv.textContent = message;
          messageDiv.classList.add("chat-message", sender + "-message");
          chatHolder.appendChild(messageDiv);
        }

        // Example function to add bot's reply
        function botReply(message) {
          addMessage(message, "bot");
        }





        // startRecordingButton.addEventListener("click", () => {


        //   startRecordingButton.disabled = true;
        //   stopRecordingButton.disabled = false;


        // });

        // stopRecordingButton.addEventListener("click", () => {
        //   // mediaRecorder.stop();
        //   startRecordingButton.disabled = false;
        //   stopRecordingButton.disabled = true;




        // });


      });
    </script>
</body>

</html>